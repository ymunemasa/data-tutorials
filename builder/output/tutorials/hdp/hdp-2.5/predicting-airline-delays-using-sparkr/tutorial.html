<div class="tutorial-content">
  <h1 id="predicting-airline-delays-using-sparkr">Predicting Airline Delays using SparkR</h1>

<h2 id="introduction">Introduction</h2>

<p>R is a popular tool for statistics and data analysis. It has rich visualization capabilities and a large collection of libraries that have been developed and maintained by the R developer community. One drawback to R is that it’s designed to run on in-memory data, which makes it unsuitable for large datasets.</p>

<p>Spark is a distributed engine for processing many Terabytes of data. It is a versatile tool with capabilities for data processing, SQL analysis, streaming and machine learning. Because Spark is a distributed framework a Hortonworks cluster running Spark can process many Terabytes of data in a short amount of time.</p>

<p>SparkR combines the benefits of Spark and R by allowing Spark jobs to be called from within R. This allows the analyst to leverage Spark’s ability to build aggregate statistics over large, multi-Terabyte datasets and then bring the smaller aggregated data back into R for visualization and analysis.</p>

<p>In this tutorial we’ll show you how to use SparkR to predict flight delays using Logistic Regression. We’ll be using RStudio as our IDE for building R models.</p>

<h2 id="prerequisites">Prerequisites</h2>

<ul>
  <li>Download and install the latest <a href="https://hortonworks.com/downloads/">Hortonworks Sandbox</a></li>
  <li><a href="https://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a> to get used to Sandbox.</li>
  <li>Follow this <a href="https://community.hortonworks.com/content/kbentry/69424/setting-up-rstudio-on-hortonworks-docker-sandbox-2.html">article</a> on Hortonworks Community to install RStudio on the Sandbox.</li>
</ul>

<h2 id="outline">Outline</h2>
<ul>
  <li><a href="#step-1-download-the-dataset">Step 1 : Download the Dataset</a></li>
  <li><a href="#step-2-setup-sparkr-on-rstudio">Step 2 : Setup SparkR on RStudio</a></li>
  <li><a href="#step-3-prepare-a-training-dataset">Step 3 : Prepare a Training Dataset</a></li>
  <li><a href="#step-4-exploratory-data-analysis">Step 4 : Exploratory Data Analysis</a></li>
  <li><a href="#step-5-regression-model-to-predict-airline-delay">Step 5 : Regression Model to predict Airline delay</a></li>
  <li><a href="#step-6-logistic-regression-to-predict-airline-delay">Step 6 : Logistic Regression to predict Airline delay</a></li>
  <li><a href="#summary">Summary</a></li>
</ul>

<h2 id="step-1--download-the-dataset">Step 1 : Download the Dataset</h2>

<p>Every year approximately 20% of airline flights are delayed or cancelled, resulting in significant costs to both travelers and airlines. As our example use-case, we will build a supervised learning model that predicts airline delay from historical flight data. Download the dataset from here and which includes details about flights in the US for 2015. Every row in the dataset has 16 attributes:</p>

<ul>
  <li>Year</li>
  <li>Month</li>
  <li>Day of Month</li>
  <li>Day of Week</li>
  <li>Flight Number</li>
  <li>Origin</li>
  <li>Destination</li>
  <li>Departure Time</li>
  <li>Departure Delay</li>
  <li>Arrival Time</li>
  <li>Arrival Delay</li>
  <li>Cancelled</li>
  <li>Cancellation Code</li>
  <li>Air Time</li>
  <li>Distance</li>
</ul>

<p>After you download the file, unzip it and upload train_df.csv and test_df.csv to the /tmp directory of HDFS using Files View. Open Ambari by going to 127.0.0.1:8888 and click on “Launch Dashboard”. Once in Ambari, select “Files View” from the second menu in the upper right hand corner.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/fileView.png" alt="Files View" /></p>

<p>Click on /tmp folder and upload these two files. Your screen should look like this:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/fileView2.png" alt="Files View 2" /></p>

<h2 id="step-2--setup-sparkr-on-rstudio">Step 2 : Setup SparkR on RStudio</h2>

<p>Next, let us login to RStudio using credentials amy_ds/amy_ds. We have to create a SparkContext object which connects the R program to the cluster. You can create it using sparkR.init(). We also need a SqlContext object to work with data frames which can be created from SparkContext.</p>

<p>Let us start with creating an environment variable SPARK_HOME which has the location of Spark Libraries. We will load the SparkR package and we invoke sparkR.init() function to create SparkContext. We are also adding some Spark Driver properties and csv package so that the SparkR data frame can read csv files.</p>

<p>Type the following lines on RStudio console:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>if (nchar(Sys.getenv("SPARK_HOME")) &lt; 1) {
  Sys.setenv(SPARK_HOME = "/usr/hdp/current/spark")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sc &lt;- sparkR.init(master = "local[*]", sparkEnvir = list(spark.driver.memory="2g"),sparkPackages="com.databricks:spark-csv_2.10:1.4.0")
sqlContext &lt;- sparkRSQL.init(sc)

</code></pre>
</div>
<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R1.png" alt="R1" /></p>

<p>Press Enter</p>

<h2 id="step-3--prepare-a-training-dataset">Step 3 : Prepare a Training dataset</h2>

<p>Before moving ahead, check out the SparkR documentation here to get used to SparkR API. You can either create a SparkR dataframe from the local R data frame or data sources in formats like csv or from Hive tables. We are going to use read.df() function to read the file from a data source (HDFS in our case), retain the schema and create the SparkR data frame. Type this line to create a dataframe taking the data from /tmp/train_df.csv file with headers included</p>

<p><code class="highlighter-rouge">train_df &lt;- read.df(sqlContext,"/tmp/train_df.csv","csv", header = "true", inferSchema = "true")</code></p>

<p>After it gets loaded, you can view the dataframe by:</p>

<p><code class="highlighter-rouge">head(train_df)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R2.png" alt="R2" /></p>

<p>It shows the top 6 records of the dataframe, you can also see the variables and the type of variables to the right side of the screen.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R3.png" alt="R3" /></p>

<p>Next, let us try to add some more columns to our dataframe to make the data more powerful and informative.</p>

<p>We will begin with deciding whether the following data is weekend or not. If it is weekend, enter 1 or else 0. The weekend starts from Friday and ends on Sunday. Enter the following:</p>

<p><code class="highlighter-rouge">train_df$WEEKEND &lt;- ifelse(train_df$DAY_OF_WEEK == 5 | train_df$DAY_OF_WEEK == 6 | train_df$DAY_OF_WEEK == 7,1,0)</code></p>

<p>It uses ifelse() function which checks whether the value of DAY_OF_WEEK variable is 5, 6 or 7 and adds the value(1,0) to the new column WEEKEND corresponding to that.</p>

<p>Next, create a new column called DEP_HOUR which will have extracted hour value from DEP_TIME column.</p>

<p><code class="highlighter-rouge">train_df$DEP_HOUR &lt;- floor(train_df$DEP_TIME/100)</code></p>

<p>Now, let us introduce one more column called DELAY_LABELED which has value 1 if the arrival delay(ARR_DELAY) is more than 15 minutes and 0 if ARR_DELAY is less than 15 minutes. That means all flights which are arrived 15 minutes delayed are considered to be delayed.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>train_df$DELAY_LABELED &lt;- ifelse(train_df$ARR_DELAY &gt; 15, 1, 0)
train_df$DELAY_LABELED &lt;- cast(train_df$DELAY_LABELED,"integer")
</code></pre>
</div>

<p>We will keep only those flight records where it did not get cancelled. In the next statement, we are filtering out those records where the value of CANCELLED was 1</p>

<p><code class="highlighter-rouge">train_df &lt;- train_df[train_df$CANCELLED == 0,]</code></p>

<p>Next cleansing will be for NA values. After looking a dataset for a while, you will see that there are lot of NA values in ARR_DELAY column. We should keep only those where we have valid readings of ARR_DELAY.</p>

<p><code class="highlighter-rouge">train_df &lt;- train_df[train_df$ARR_DELAY != "NA",]</code></p>

<p>Next, if you want to know the datatype of columns in SparkR dataframe, just type
<code class="highlighter-rouge">printSchema(train_df)</code></p>

<p>You should see following console output:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R4.png" alt="R4" /></p>

<p>We should convert the type of ARR_DELAY and DEP_DELAY from string to integer so that we can perform mathematical operations on that.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>train_df$ARR_DELAY &lt;- cast(train_df$ARR_DELAY,"integer")
train_df$DEP_DELAY &lt;- cast(train_df$DEP_DELAY,"integer")
</code></pre>
</div>

<p>Type <code class="highlighter-rouge">head(train_df)</code> to view the prepared dataframe.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R5.png" alt="R5" /></p>

<h2 id="step-4--exploratory-data-analysis">Step 4 : Exploratory Data Analysis</h2>

<p>At the end of this tutorial, we will be able to predict which flight is likely to be delayed. We can classify our dataset into two values- 0 or 1 (0 for flights on time and 1 for flights delayed). But before creating a model, let us visualize the data what we have right now.</p>

<p>We create a new dataframe called delay which will have two columns, DELAY_LABELED and the count of it. Basically it will have a count of delayed flights and ontime flights. We will be using aggregate function of SparkR where we group the dataframe by DELAY_LABELED and calculating the count using n().</p>

<p><code class="highlighter-rouge">delay &lt;- agg(group_by(train_df, train_df$DELAY_LABELED), count = n(train_df$DELAY_LABELED))</code></p>

<p>Introduce a new column called STATUS which will have value ontime if DELAY_LABELED is 0 and delayed if DELAY_LABELED is 1.</p>

<p><code class="highlighter-rouge">delay$STATUS &lt;- ifelse(delay$DELAY_LABELED == 0, "ontime", "delayed")</code></p>

<p>Delete a first column DELAY_LABELED because we do not need it anymore.</p>

<p><code class="highlighter-rouge">delay &lt;- delay[,-1]</code></p>

<p>Next, let us convert this SparkR dataframe to R dataframe using as.data.frame() function to visualize it using ggplot, let us call this new dataframe delay_r.</p>

<p><code class="highlighter-rouge">delay_r &lt;- as.data.frame(delay)</code>`</p>

<p>Add Percentage as one more column to this new dataframe.</p>

<p><code class="highlighter-rouge">delay_r$Percentage &lt;- (delay_r$count / sum(delay_r$count)) * 100</code>
<code class="highlighter-rouge">delay_r$Percentage &lt;- round(delay_r$Percentage,2)</code></p>

<p>View the dataframe:</p>

<p><code class="highlighter-rouge">head(delay_r)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R6.png" alt="R6" /></p>

<p>Next, install and import the package called ggplot2. ggplot2 is a plotting system for R based on the grammar of graphics. You can plot graphs like bar chart, stacked bar chart, line chart, pie chart, scatter plot and histograms.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>install.packages("ggplot2")
library(ggplot2)
</code></pre>
</div>

<p>Wait for it to get completed. Create a blank theme to delete the axis titles and ticks and setting the size for plot title.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>blank_theme &lt;- theme_minimal()+
    theme(
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.border = element_blank(),
        panel.grid=element_blank(),
        axis.ticks = element_blank(),
        plot.title=element_text(size=14, face="bold")
    )
</code></pre>
</div>

<p>We will draw a pie chart showing the percentage of delayed and ontime flights.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ggplot(delay_r, aes(x="",y=Percentage,fill=STATUS)) + geom_bar(stat="identity",width=1,colour="green") + coord_polar(theta="y",start=0) + blank_theme + ggtitle("Pie Chart for Flights") + theme(axis.text.x=element_blank()) + geom_text(aes(y = Percentage/2,label = paste0(Percentage,"%"),hjust=2))
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R7.png" alt="R7" /></p>

<p>Click on Zoom at the top of the chart to have a clearer view.</p>

<p>This graph shows that around 18.17% flights are getting delayed which is a very big figure.</p>

<p>Let us explore what effect Day_Of_Week has on the dataset. We will create two new dataframes called delay_flights and non_delay_flights which will have details for delayed and ontime flights respectively.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>delay_flights &lt;- filter(train_df,train_df$DELAY_LABELED == 1)
non_delay_flights &lt;- filter(train_df,train_df$DELAY_LABELED == 0)
</code></pre>
</div>

<p>Next, we will find the count of delayed and ontime flights grouped by Day_Of_Week.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>delay_flights_count &lt;- agg(group_by(delay_flights,delay_flights$DAY_OF_WEEK), DELAY_COUNT = n(delay_flights$DELAY_LABELED))
non_delay_flights_count &lt;- agg(group_by(non_delay_flights,non_delay_flights$DAY_OF_WEEK), NON_DELAY_COUNT = n(non_delay_flights$DELAY_LABELED))
</code></pre>
</div>

<p>Now, we can merge both delay_flights_count and non_delay_flights_count dataframes.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dayofweek_count &lt;- merge(delay_flights_count, non_delay_flights_count, by.delay_flights_count = DAY_OF_WEEK, by.non_delay_flights_count = DAY_OF_WEEK)
</code></pre>
</div>

<p>When you merge two dataframes, you get common column twice in the dataframe which is not required. Let us delete that by typing:</p>

<p><code class="highlighter-rouge">dayofweek_count$DAY_OF_WEEK_y &lt;- NULL</code></p>

<p>Rename the column using withColumnRenamed() function.</p>

<p><code class="highlighter-rouge">dayofweek_count &lt;- withColumnRenamed(dayofweek_count,"DAY_OF_WEEK_x","DAY_OF_WEEK")</code></p>

<p>Convert this SparkR Dataframe to R dataframe so that we can run visualization on it:</p>

<p><code class="highlighter-rouge">dayofweek_count_r &lt;- as.data.frame(dayofweek_count)</code></p>

<p>Let us view this new R dataframe:
<code class="highlighter-rouge">head(dayofweek_count_r)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R8.png" alt="R8" /></p>

<p>Introduce two columns, Delayed and Ontime, which have the percentage values for DELAY_COUNT and NON_DELAY_COUNT respectively.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dayofweek_count_r$Delayed &lt;- (dayofweek_count_r$DELAY_COUNT/(dayofweek_count_r$DELAY_COUNT+dayofweek_count_r$NON_DELAY_COUNT)) * 100
dayofweek_count_r$Ontime &lt;- (dayofweek_count_r$NON_DELAY_COUNT/(dayofweek_count_r$DELAY_COUNT+dayofweek_count_r$NON_DELAY_COUNT)) * 100
dayofweek_count_r &lt;- dayofweek_count_r[,-2:-3]
</code></pre>
</div>

<p>Next, add one more column which represents the ratio of delayed flights against ontime flights.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dayofweek_count_r$Ratio &lt;- dayofweek_count_r$Delayed/dayofweek_count_r$Ontime * 100
dayofweek_count_r$Ratio &lt;- round(dayofweek_count_r$Ratio,2)
</code></pre>
</div>

<p>Now, if you look closely, our data is in wide format. The data is said to be in wide format if there is one observation row per subject with each measurement present as a different variable. We have to change it to long format which means there is one observation row per measurement thus multiple rows per subject. In R, we use reshape to do this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>library(reshape2)
DF1 &lt;- melt(dayofweek_count_r, id.var="DAY_OF_WEEK")
DF1$Ratio &lt;- DF1[15:21,3]
</code></pre>
</div>

<p>View this new long format dataframe:</p>

<p><code class="highlighter-rouge">DF1</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R9.png" alt="R9" /></p>

<p>We will change this dataframe just to make the plot more clearer.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>DF1 &lt;- DF1[-15:-21,]
DF1[8:14,4] &lt;- NA
</code></pre>
</div>

<p>Next, run the following line to see the stacked bar chart:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>install.packages("ggrepel")
library(ggrepel)
ggplot(DF1, aes(x=DAY_OF_WEEK,y=value,fill=variable)) + geom_bar(stat="identity") + geom_path(aes(y=Ratio,color="Ratio of Delayed flights against Non Delayed Flights")) + geom_text_repel(aes(label=Ratio), size = 3) + ggtitle("Percentage of Flights Delayed") + labs(x="Day of Week",y="Percentage")
</code></pre>
</div>

<p>Click on Zoom button.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R10.png" alt="R10" /></p>

<p>As you can see here, most delays are happening on Monday and Thursday. It drops during the start of the weekend but again rises up by Sunday.</p>

<p>Now we will look over Destination effect on the delays,</p>

<p>Create two new dataframes from delay_flights and non_delay_flights  dataframes respectively which will have the count of flights specific to some Destinations like LAX, SFO, HNL, PDX.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>destination_delay_count &lt;- agg(group_by(delay_flights,delay_flights$DEST), DELAY_COUNT = n(delay_flights$DELAY_LABELED))
destination_delay_count &lt;- destination_delay_count[(destination_delay_count$DEST == "LAX" | destination_delay_count$DEST == "SFO" | destination_delay_count$DEST == "HNL" | destination_delay_count$DEST == "PDX") ,]

destination_non_delay_count &lt;- agg(group_by(non_delay_flights,non_delay_flights$DEST), NON_DELAY_COUNT = n(non_delay_flights$DELAY_LABELED))
destination_non_delay_count &lt;- destination_non_delay_count[(destination_non_delay_count$DEST == "LAX" | destination_non_delay_count$DEST == "SFO") | destination_delay_count$DEST == "HNL" | destination_delay_count$DEST == "PDX" ,]

</code></pre>
</div>

<p>Lets merge these two new dataframes into one.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>destination_count &lt;- merge(destination_delay_count, destination_non_delay_count, by.destination_delay_count = DEST, by.destination_non_delay_count = DEST)
destination_count$DEST_y &lt;- NULL
destination_count &lt;- withColumnRenamed(destination_count,"DEST_x","DEST")
</code></pre>
</div>

<p>And convert it into R Dataframe.</p>

<p><code class="highlighter-rouge">destination_count_r &lt;- as.data.frame(destination_count)</code>`</p>

<p>Bring up two new columns(Delayed and Ontime) which has the percentage values</p>

<div class="highlighter-rouge"><pre class="highlight"><code>destination_count_r$Delayed &lt;- (destination_count_r$DELAY_COUNT/(destination_count_r$DELAY_COUNT+destination_count_r$NON_DELAY_COUNT)) * 100
destination_count_r$Ontime &lt;- (destination_count_r$NON_DELAY_COUNT/(destination_count_r$DELAY_COUNT+destination_count_r$NON_DELAY_COUNT)) * 100
destination_count_r &lt;- destination_count_r[,-2:-3]
</code></pre>
</div>

<p>Introduce one more column called Ratio which has the proportion of delayed flights against ontime flights on the four aforementioned destinations</p>
<div class="highlighter-rouge"><pre class="highlight"><code>destination_count_r$Ratio &lt;- destination_count_r$Delayed/destination_count_r$Ontime * 100
destination_count_r$Ratio &lt;- round(destination_count_r$Ratio,2)
</code></pre>
</div>

<p>As earlier, let us melt down this dataframe too to create a stacked bar chart. Use melt function of reshape package.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>DF2 &lt;- melt(destination_count_r, id.var="DEST")
DF2$Ratio &lt;- DF2[9:12,3]
DF2 &lt;- DF2[-9:-12,]
DF2[5:8,4] &lt;- NA
</code></pre>
</div>

<p>Draw a stacked bar chart:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>ggplot(DF2, aes(x=DEST,y=value,fill=variable)) + geom_bar(stat="identity") + geom_path(aes(y=Ratio,color="Ratio of Delayed flights against Non Delayed Flights"),group = 1) + geom_text_repel(aes(label=Ratio), size = 3) + ggtitle("Percentage of Flights Delayed by Destination") + labs(x="Destinations",y="Percentage")
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R11.png" alt="R11" /></p>

<p>Looks like smaller city Destination has the most delayed ratio. Let us do the same thing with Origins also. Create two new dataframes having records only where Origins are SNA, ORD, JFK and IAH.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>origin_delay_count &lt;- agg(group_by(delay_flights,delay_flights$ORIGIN), DELAY_COUNT = n(delay_flights$DELAY_LABELED))
origin_delay_count &lt;- origin_delay_count[(origin_delay_count$ORIGIN == "SNA" | origin_delay_count$ORIGIN == "ORD" | origin_delay_count$ORIGIN == "JFK" | origin_delay_count$ORIGIN == "IAH") ,]
origin_non_delay_count &lt;- agg(group_by(non_delay_flights,non_delay_flights$ORIGIN), NON_DELAY_COUNT = n(non_delay_flights$DELAY_LABELED))
origin_non_delay_count &lt;- origin_non_delay_count[(origin_non_delay_count$ORIGIN == "SNA" | origin_non_delay_count$ORIGIN == "ORD" | origin_delay_count$ORIGIN == "JFK" | origin_delay_count$ORIGIN == "IAH") ,]
</code></pre>
</div>

<p>Merge dataframes by using merge function of SparkR API and convert it into R Dataframe:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>origin_count &lt;- merge(origin_delay_count, origin_non_delay_count, by.origin_delay_count = ORIGIN, by.origin_non_delay_count = ORIGIN)
origin_count$ORIGIN_y &lt;- NULL
origin_count &lt;- withColumnRenamed(origin_count,"ORIGIN_x","ORIGIN")
origin_count_r &lt;- as.data.frame(origin_count)
</code></pre>
</div>

<p>Add three columns - Delayed(Percentage), Ontime(Percentage) and Ratio(Delayed/Ontime)</p>

<div class="highlighter-rouge"><pre class="highlight"><code>origin_count_r$Delayed &lt;- (origin_count_r$DELAY_COUNT/(origin_count_r$DELAY_COUNT+origin_count_r$NON_DELAY_COUNT)) * 100
origin_count_r$Ontime &lt;- (origin_count_r$NON_DELAY_COUNT/(origin_count_r$DELAY_COUNT+origin_count_r$NON_DELAY_COUNT)) * 100
origin_count_r &lt;- origin_count_r[,-2:-3]
origin_count_r$Ratio &lt;- origin_count_r$Delayed/origin_count_r$Ontime * 100
origin_count_r$Ratio &lt;- round(origin_count_r$Ratio,2)
</code></pre>
</div>

<p>As earlier, make the dataframe in long format using melt() and draw the stacked bar chart:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>DF3 &lt;- melt(origin_count_r, id.var="ORIGIN")
DF3$Ratio &lt;- DF3[9:12,3]
DF3 &lt;- DF3[-9:-12,]
DF3[5:8,4] &lt;- NA

ggplot(DF3, aes(x=ORIGIN,y=value,fill=variable)) + geom_bar(stat="identity") + geom_path(aes(y=Ratio,color="Ratio of Delayed flights against Non Delayed Flights"),group = 1) + geom_text_repel(aes(label=Ratio), size = 3) + ggtitle("Percentage of Flights Delayed by Origin") + labs(x="Origins",y="Percentage")
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R12.png" alt="R12" /></p>

<p>As you can see here, smaller city Origin(SNA) has a least delay ratio.</p>

<h2 id="step-5--regression-model-to-predict-airline-delay">Step 5 : Regression Model to Predict Airline Delay</h2>

<p>Now that we have explored the data, let’s predict how much delayed the flight would be.
SparkR allows the fitting of generalized linear models over DataFrames using the glm() function. Under the hood, SparkR uses MLlib to train a model of the specified family. The gaussian and binomial families are supported in 1.6 version.
We are going to choose some variables as independent variables to predict the output variable which in our case is ARR_DELAY.</p>

<p><code class="highlighter-rouge">train_df_glm &lt;- glm(ARR_DELAY ~ MONTH + DEP_HOUR + DEP_DELAY + WEEKEND + ORIGIN + DEST, data = train_df,  family = "gaussian")</code>`</p>

<p>You should get a note that your job has been finished. Now, you return the summary of your model which is same as R’ native model summary.</p>

<p><code class="highlighter-rouge">summary(train_df_glm)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R13.png" alt="R13" /></p>

<p>It returned a list of devianceResiduals and coefficients. Deviance Residuals signifies the maximum and minimum value that ARR_DELAY can have. We also see that DEP_DELAY variable has a positive effect on ARR_DELAY which means if there is a departure delay, then the arrival delay will be there most of the time. As the value of Month increases from 1 towards 8, the ARR_DELAY decreases. Same is happening with DEP_HOUR but these are very small impacts. The variable WEEKEND is making a good negative impact, we can infer that there are less delays during weekends.</p>

<p>In Origins and Destinations, if you see clearly, most of the origins has a negative effect but destinations has a positive effect on the ARR_DELAY.</p>

<p>We can also make predictions based on the model on the test data. Let us create a test data which has airline data from the month September to December of 2015. Follow the same procedure which we did during the preparation of training data.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>test_df &lt;- read.df(sqlContext,"/tmp/test_df.csv","csv", header = "true", inferSchema = "true")
test_df$WEEKEND &lt;- ifelse(test_df$DAY_OF_WEEK == 5 | test_df$DAY_OF_WEEK == 6 | test_df$DAY_OF_WEEK == 7,1,0)
test_df$DEP_HOUR &lt;- floor(test_df$DEP_TIME/100)
test_df$DELAY_LABELED &lt;- ifelse(test_df$ARR_DELAY &gt; 15, 1, 0)
test_df$DELAY_LABELED &lt;- cast(test_df$DELAY_LABELED,"integer")
test_df &lt;- test_df[test_df$CANCELLED == 0,]
test_df &lt;- test_df[test_df$ARR_DELAY != "NA",]
test_df &lt;- test_df[test_df$ORIGIN != "SBN",]
test_df &lt;- test_df[test_df$DEST != "SBN",]
test_df$ARR_DELAY &lt;- cast(test_df$ARR_DELAY,"integer")
test_df$DEP_DELAY &lt;- cast(test_df$DEP_DELAY,"integer")
</code></pre>
</div>

<p>Next, calculate the predicted probability of ARR_DELAY  bu using predict function.</p>

<p><code class="highlighter-rouge">predictions &lt;- predict(train_df_glm, newData = test_df)</code></p>

<p>We can compare the actual values with the predicted values, type this:</p>

<p><code class="highlighter-rouge">head(select(predictions, "ARR_DELAY", "prediction"))</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R14.png" alt="R14" /></p>

<p>As you have already noticed, the summary function do not provide enough details as of now. Since we do not have enough information, we should calculate R2 of our model. R-squared is a statistical measure of how close the data are to the fitted regression line.</p>

<p>Firstly, we will calculate the mean of ARR_DELAY that will be used as a reference to the base predictor model.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ARR_DELAY_mean &lt;- collect(agg(
    train_df,
    AVG_ARR_DELAY=mean(train_df$ARR_DELAY)
))$AVG_ARR_DELAY
</code></pre>
</div>

<p>The mean value turns out to be 4.496468
Let’s add the squared residuals and squared totals so later on we can calculate R2.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>predictions$Squared_res &lt;- (predictions$ARR_DELAY - predictions$prediction)**2
predictions$Squared_tot &lt;- (predictions$ARR_DELAY - ARR_DELAY_mean)**2
</code></pre>
</div>

<p>Let us view the predictions data frame now.</p>

<p><code class="highlighter-rouge">head(select(predictions, "ARR_DELAY", "prediction", "Squared_res", "Squared_tot"))</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R15.png" alt="R15" /></p>

<p>Next, take out the sum of squared residuals and squared totals,</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Squared_res_sum &lt;- collect(agg(
predictions,
SUM_SQUARED_RES=sum(predictions$Squared_res)
))$SUM_SQUARED_RES

Squared_tot_sum &lt;- collect(agg(
predictions,
SUM_SQUARED_TOT=sum(predictions$Squared_tot)
))$SUM_SQUARED_TOT
</code></pre>
</div>

<p>Now the formula to calculate R2 is</p>

<p><code class="highlighter-rouge">R2 &lt;- 1.0 - (Squared_res_sum/Squared_tot_sum)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R16.png" alt="R16" /></p>

<p>It comes out to be 0.9023864. An R2 of 1 indicates that the regression line perfectly fits the data.</p>

<h2 id="step-6--logistic-regression-to-predict-airline-delay">Step 6 : Logistic Regression to predict Airline Delay</h2>

<p>So far we have predicted the continuous variable by the above model. Now it is time to predict whether the flight will be delayed or not. It will be like a binary classification where we will bucket flights into delayed and ontime. But before ahead towards the development of the model, we have to some transformation to our dataset. The first transformation that we have to do is to convert the categorical variables into dummy variables. Five categorical variables are:
    1.	Day of Week
    2.	Carrier
    3.	Destination
    4.	Origin
    5.	Departure Hour</p>

<p>We are going to use a function in R called model.matrix() where each value of these columns will be a separate column and will carry only either two values - 0 or 1. Lets subset the training data into just these five variables and DELAY_LABELED which again is the categorical variable and our output variable in this case.</p>

<p><code class="highlighter-rouge">dummy &lt;- subset(train_df, select = c(4,5,7,8,18,19))</code></p>

<p>Next, we are going to typecast DAY_OF_WEEK and DEP_HOUR from integer to string so that it gets broken down easily.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy$DAY_OF_WEEK &lt;- cast(dummy$DAY_OF_WEEK,"string")
dummy$DEP_HOUR &lt;- cast(dummy$DEP_HOUR,"string")
</code></pre>
</div>

<p>Subsetting the dataset further to only include specific origins and destinations.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy &lt;- dummy[(dummy$ORIGIN == "SNA" | dummy$ORIGIN == "ORD" | dummy$ORIGIN == "HNL") ,]
dummy &lt;- dummy[(dummy$DEST == "LAX" | dummy$DEST == "SFO" | dummy$DEST == "JFK") ,]
</code></pre>
</div>

<p>Now, convert this SparkR dataframe into R dataframe to make use of model.matrix() function</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy_r &lt;- as.data.frame(dummy)
dummy_matrix1 &lt;- model.matrix(~DAY_OF_WEEK+CARRIER+DEST+ORIGIN,data=dummy_r)
dummy_matrix1 &lt;- dummy_matrix1[,-1]
</code></pre>
</div>

<p>As there are lot of values for DEP_HOUR, we are going run to model.matrix() separately and combine these two matrices later.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy_matrix2 &lt;- model.matrix(~DEP_HOUR,data=dummy_r)
dummy_matrix2 &lt;- dummy_matrix2[,-1]
</code></pre>
</div>

<p>Use cbind function to join two matrices</p>

<p><code class="highlighter-rouge">dummy_matrix &lt;- cbind(dummy_matrix1,dummy_matrix2)</code></p>

<p>Convert the matrix to the dataframe so that you can create the model on that.</p>

<p><code class="highlighter-rouge">dummy_df &lt;- as.data.frame(dummy_matrix)</code></p>

<p>We need DELAY_LABELED from the previous dataframe and add it to this new dataframe</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy_df &lt;- cbind(dummy_df,dummy_r$DELAY_LABELED)
colnames(dummy_df)[ncol(dummy_df)] &lt;- "DELAY_LABELED"
</code></pre>
</div>

<p>In order to create a Logistic Regression model out of this dataframe, we will convert it into SparkR dataframe</p>

<p><code class="highlighter-rouge">dummy_df_sparkR &lt;- createDataFrame(sqlContext,dummy_df)</code></p>

<p>It is important to know how your dataframe looks like right now.</p>

<p><code class="highlighter-rouge">head(dummy_df_sparkR)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R17.png" alt="R17" /></p>

<p>Run the model having DELAY_LABELED as the output variable and all other variables as input/independent variables.</p>

<p><code class="highlighter-rouge">dummy_df_glm &lt;- glm(DELAY_LABELED ~ ., data = dummy_df_sparkR,  family = "gaussian")</code></p>

<p>Check the summary of the model:</p>

<p><code class="highlighter-rouge">summary(dummy_df_glm )</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R18.png" alt="R18" /></p>

<p>You can notice effects of different variables here.</p>

<p>Prepare your test data from last 4 months data. Follow the same procedure what we did in preparing the training data.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dummy_test &lt;- subset(test_df, select = c(4,5,7,8,18,19))
dummy_test$DAY_OF_WEEK &lt;- cast(dummy_test$DAY_OF_WEEK,"string")
dummy_test$DEP_HOUR &lt;- cast(dummy_test$DEP_HOUR,"string")
dummy_test &lt;- dummy_test[(dummy_test$ORIGIN == "SNA" | dummy_test$ORIGIN == "ORD" | dummy_test$ORIGIN == "HNL") ,]
dummy_test &lt;- dummy_test[(dummy_test$DEST == "LAX" | dummy_test$DEST == "SFO" | dummy_test$DEST == "JFK") ,]
dummy_test_r &lt;- as.data.frame(dummy_test)
dummy_test_matrix1 &lt;- model.matrix(~DAY_OF_WEEK+CARRIER+DEST+ORIGIN,data=dummy_test_r)
dummy_test_matrix1 &lt;- dummy_test_matrix1[,-1]
dummy_test_matrix2 &lt;- model.matrix(~DEP_HOUR,data=dummy_test_r)
dummy_test_matrix2 &lt;- dummy_test_matrix2[,-1]

dummy_test_matrix &lt;- cbind(dummy_test_matrix1,dummy_test_matrix2)
dummy_test_df &lt;- as.data.frame(dummy_test_matrix)
dummy_test_df &lt;- cbind(dummy_test_df,dummy_test_r$DELAY_LABELED)
colnames(dummy_test_df)[ncol(dummy_test_df)] &lt;- "DELAY_LABELED"

dummy_test_df_sparkR &lt;- createDataFrame(sqlContext,dummy_test_df)
</code></pre>
</div>

<p>Next, use predict function to predict the values</p>

<p><code class="highlighter-rouge">predictions &lt;- predict(dummy_df_glm, newData = dummy_test_df_sparkR)</code></p>

<p>View the actual value along with the predicted value.</p>

<p><code class="highlighter-rouge">head(select(predictions, "DELAY_LABELED", "prediction"))</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R19.png" alt="R19" /></p>

<p>Let us see how accurate our model is. As you can see, minimum value of predicted value is -0.70 and maximum value is 1.06. Introduce a new column binary which will have value 1 when prediction is more than threshold(0.3 in our case) and 0 when it is less than 0.3.</p>

<p><code class="highlighter-rouge">predictions$binary &lt;- ifelse(predictions$prediction &gt; 0.3 , 1, 0)</code></p>

<p>Create two new dataframes which has the count of actual and predicted values respectively.</p>
<div class="highlighter-rouge"><pre class="highlight"><code>actualResults &lt;- agg(group_by(predictions,predictions$label), Actual = n(predictions$label))
predictedResults &lt;- agg(group_by(predictions,predictions$binary), Predicted = n(predictions$binary))

</code></pre>
</div>
<p>Join these dataframes and delete one of the common column.
<code class="highlighter-rouge">results &lt;- join(actualResults, predictedResults, actualResults$label == predictedResults$binary)</code>
<code class="highlighter-rouge">results$binary &lt;- NULL</code></p>

<p>Print the dataframe to check the prediction.
<code class="highlighter-rouge">head(results)</code></p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/predicting-airline-delays-using-sparkr/assets/R20.png" alt="R20" /></p>

<p>This signifies that the flight got delayed 1635 times but predicted 2146 by the model. They were ontime 5849 times but predicted 5338 times by the model.</p>

<h2 id="summary">Summary</h2>

<p>Congratulations, you now know how to use SparkR.  If you want to learn more about using Apache Spark for machine learning and processing large datasets please check out these tutorials:</p>
<ul>
  <li><a href="https://hortonworks.com/hadoop-tutorial/hands-on-tour-of-apache-spark-in-5-minutes/">5-Minute tour of Apache Spark</a></li>
  <li><a href="https://hortonworks.com/hadoop-tutorial/intro-machine-learning-apache-spark-apache-zeppelin/">Intro to Machine Learning with Spark</a></li>
</ul>

</div>

<hr>

<div id="tutorial-footer">
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>

  <p>If you need help or have questions with this tutorial, please check HCC for answers to existing questions about this tutorial by using the Find Answers button below.  You can post a new HCC question by using the Ask Questions button below.</p>

  <p>
    <a class="btn" href="https://community.hortonworks.com/topics/tutorial-760.html" role="button">Find Answers</a>
    <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-760&amp;topics=hdp-2.5.0" role="button">Ask Questions</a>
  </p>

  <p>Tutorial Name: <strong>Predicting Airline Delays using SparkR</strong></p>
  <p>HCC Tags:<strong> tutorial-760</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple components please indicate which one your question relates to.</p>

  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks GitHub repository and can be contributed to by following the <a href="https://github.com/hortonworks/big-data-tutorials/wiki">Tutorial Contribution Guide</a>.  For issues/bugs/feedback, please <a href="https://github.com/hortonworks/big-data-tutorials/issues/new">submit an issue</a> and we will do our best to resolve it!</p>
</div>

